COMMENTARY_TEXT = """

Preparing data for training a Large Language Model (LLM) involves several key steps:

1. **ğŸ“š Identify the corpus of data**: Large and diverse set of text data that the model will learn from.
2. **ğŸ” Break down the data into tokens**: Tokenize the identified data into smaller units (tokens) that the model can process.
3. **ğŸ“– Generate dictionary**: Create a dictionary of unique tokens, sorted and ranked, to be used by the model during training.
"""