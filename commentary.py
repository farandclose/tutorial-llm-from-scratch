COMMENTARY_TEXT = """

Preparing data for training a Large Language Model (LLM) involves several key steps:

1. **📚 Identify the corpus of data**: Large and diverse set of text data that the model will learn from.
2. **🔍 Break down the data into tokens**: Tokenize the identified data into smaller units (tokens) that the model can process.
3. **📖 Generate dictionary**: Create a dictionary of unique tokens, sorted and ranked, to be used by the model during training.
"""